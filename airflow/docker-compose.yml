version: '2.1'
services:
    redis:
        image: 'redis:5.0.5'
        command: redis-server --requirepass redispass
    postgres:
        image: postgres:9.6
        environment:
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow
        volumes:
            - ./db-data:/var/lib/postgresql/data
        ports:
            - "5432:5432"
    webserver:
        build: .
        restart: always
        depends_on:
            - postgres
        environment:
            - LOAD_EX=n
            - FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
            - EXECUTOR=Celery
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow
            - REDIS_PASSWORD=redispass
        volumes:
            - ./dags:/usr/local/airflow/dags
            # Uncomment to include custom plugins
            - ./plugins:/usr/local/airflow/plugins
            - ./data:/usr/local/airflow/data
            -  /var/run/docker.sock:/var/run/docker.sock:ro
        ports:
            - "8080:8080"
        command: webserver
        healthcheck:
            test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
            interval: 30s
            timeout: 30s
            retries: 3
    flower:
        #image: puckel/docker-airflow:1.10.4
        build: .
        restart: always
        depends_on:
            - redis
        environment:
            - EXECUTOR=Celery
            - REDIS_PASSWORD=redispass
        ports:
            - "5555:5555"
        command: flower
    scheduler:
        #image: puckel/docker-airflow:1.10.4
        build: .
        restart: always
        depends_on:
            - webserver
        volumes:
            - ./dags:/usr/local/airflow/dags
            # Uncomment to include custom plugins
            - ./plugins:/usr/local/airflow/plugins
        environment:
            - LOAD_EX=n
            - FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
            - EXECUTOR=Celery
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow
            - REDIS_PASSWORD=redispass
        command: scheduler
    worker:
        #image: puckel/docker-airflow:1.10.4
        build: .
        restart: always
        depends_on:
            - scheduler
        volumes:
            - ./dags:/usr/local/airflow/dags
            # Uncomment to include custom plugins
            - ./plugins:/usr/local/airflow/plugins
            - ./data:/usr/local/airflow/data
            -  /var/run/docker.sock:/var/run/docker.sock:ro
        environment:
            - FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
            - EXECUTOR=Celery
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow
            - REDIS_PASSWORD=redispass
        command: worker
#    spark-master:
#        image: altr/spark
#        container_name: spark-master
#        ports:
#            - "8088:8080"
#            - "7077:7077"
#        environment:
#            - INIT_DAEMON_STEP=setup_spark
#        volumes:
#            - ./simple-app:/simple-app
#            - ./data/raw:/data/raw
#            - ./data/processed/:/data/processed
#    spark-worker-1:
#        image: altr/spark
#        container_name: spark-worker-1
#        depends_on:
#            - spark-master
#        ports:
#            - "8089:8081"
#        environment:
#            - "SPARK_MASTER=spark://spark-master:7077"
#        volumes:
#            - ./simple-app:/simple-app
#            - ./data/raw:/data/raw
#            - ./data/processed/:/data/processed

#    spark-master:
#        image: bde2020/spark-master:2.4.4-hadoop2.7
#        container_name: spark-master
#        ports:
#            - "8088:8080"
#            - "7077:7077"
#        environment:
#            - INIT_DAEMON_STEP=setup_spark
#        volumes:
#            - ./simple-app:/simple-app
#            - ./data/raw:/data/raw
#            - ./data/processed/:/data/processed
#    spark-worker-1:
#        image: bde2020/spark-worker:2.4.4-hadoop2.7
#        container_name: spark-worker-1
#        depends_on:
#            - spark-master
#        ports:
#            - "8089:8081"
#        environment:
#            - "SPARK_MASTER=spark://spark-master:7077"
#        volumes:
#            - ./simple-app:/simple-app
#            - ./data/raw:/data/raw
#            - ./data/processed/:/data/processed