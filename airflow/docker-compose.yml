version: '2.1'
services:
    postgres:
        image: postgres:9.6
        environment:
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow
        ports:
            - "5432:5432"
    webserver:
        build: .
        restart: always
        depends_on:
            - postgres
        environment:
            - LOAD_EX=n
            - EXECUTOR=Local
        volumes:
            - ./dags:/usr/local/airflow/dags
            # Uncomment to include custom plugins
            - ./plugins:/usr/local/airflow/plugins
            - ./data:/usr/local/airflow/data
            -  /var/run/docker.sock:/var/run/docker.sock:ro
        ports:
            - "8080:8080"
        command: webserver
        healthcheck:
            test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
            interval: 30s
            timeout: 30s
            retries: 3
    spark-master:
        image: altr/spark
        container_name: spark-master
        ports:
            - "8088:8080"
            - "7077:7077"
        environment:
            - INIT_DAEMON_STEP=setup_spark
        volumes:
            - ./simple-app:/simple-app
            - ./data/raw:/data/raw
            - ./data/processed/:/data/processed
    spark-worker-1:
        image: altr/spark
        container_name: spark-worker-1
        depends_on:
            - spark-master
        ports:
            - "8089:8081"
        environment:
            - "SPARK_MASTER=spark://spark-master:7077"
        volumes:
            - ./simple-app:/simple-app
            - ./data/raw:/data/raw
            - ./data/processed/:/data/processed

#    spark-master:
#        image: bde2020/spark-master:2.4.4-hadoop2.7
#        container_name: spark-master
#        ports:
#            - "8088:8080"
#            - "7077:7077"
#        environment:
#            - INIT_DAEMON_STEP=setup_spark
#        volumes:
#            - ./simple-app:/simple-app
#            - ./data/raw:/data/raw
#            - ./data/processed/:/data/processed
#    spark-worker-1:
#        image: bde2020/spark-worker:2.4.4-hadoop2.7
#        container_name: spark-worker-1
#        depends_on:
#            - spark-master
#        ports:
#            - "8089:8081"
#        environment:
#            - "SPARK_MASTER=spark://spark-master:7077"
#        volumes:
#            - ./simple-app:/simple-app
#            - ./data/raw:/data/raw
#            - ./data/processed/:/data/processed