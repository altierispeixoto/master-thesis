{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.window import Window\n",
    "spark = SparkSession.builder.appName('abc').getOrCreate()\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_series(start, stop, interval, alias):\n",
    "    \"\"\"\n",
    "    :param start  - lower bound, inclusive\n",
    "    :param stop   - upper bound, exclusive\n",
    "    :interval int - increment interval in seconds\n",
    "    \"\"\"\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    # Determine start and stops in epoch seconds\n",
    "    start, stop = spark.createDataFrame(\n",
    "        [(start, stop)], (\"start\", \"stop\")\n",
    "    ).select(\n",
    "        [col(c).cast(\"timestamp\").cast(\"long\") for c in (\"start\", \"stop\")\n",
    "    ]).first()\n",
    "    \n",
    "    # Create range with increments and cast to timestamp\n",
    "    return spark.range(start, stop, interval).select(\n",
    "        col(\"id\").cast(\"timestamp\").alias(alias)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext cypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: NEO4J_URL=http://neo4j:h4ck3r@172.19.0.2:7474/db/data\n"
     ]
    }
   ],
   "source": [
    "%env NEO4J_URL=http://neo4j:h4ck3r@172.19.0.2:7474/db/data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ONIBUS DE DIFERENTES LINHAS QUE SE ENCONTRAM EM UM MESMO PONTO AO LONGO DO DIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434082 rows affected.\n"
     ]
    }
   ],
   "source": [
    "results = %cypher \\\n",
    "MATCH (y:Year)-[:CONTAINS]->(m:Month)-[:CONTAINS]->(d:Day)-[:HAS_LINE]->(l:Line)-[:HAS_TRIP]->(t:Trip)-[:HAS_BUS_STOP]->(bss:BusStop) \\\n",
    "with y,m,d,l,t,bss \\\n",
    "MATCH (t)-[:HAS_EVENT]->(ev:Event)<-[:HAS_EVENT]-(h:Hour)<-[:CONTAINS]-(d) \\\n",
    "MATCH (ev)-[:IS_NEAR_BY]->(bss)  \\\n",
    "return  y.value as year, m.value as month, d.value as day, bss.number as busstop_number,bss.name as name,bss.latitude as latitude, bss.longitude as longitude, l.line_code as line_code,t.line_way as line_way, ev.vehicle as vehicle, ev.event_timestamp as event_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(results.get_dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start date is min date\n",
    "date_min=df.withColumn(\"event_timestamp\",F.date_trunc('hour', df.event_timestamp)).agg({'event_timestamp': 'min'}).first()[0]\n",
    "date_max=df.withColumn(\"event_timestamp\",F.date_trunc('hour', df.event_timestamp)).agg({'event_timestamp': 'max'}).first()[0]\n",
    "\n",
    "\n",
    "time_series5_df = generate_series(date_min, date_max, 60 * 5   , \"time_span5min\")\n",
    "time_series10_df = generate_series(date_min, date_max, 60 * 10 , \"time_span10min\")\n",
    "time_series15_df = generate_series(date_min, date_max, 60 * 15 , \"time_span15min\")\n",
    "time_series20_df = generate_series(date_min, date_max, 60 * 20 , \"time_span20min\")\n",
    "time_series25_df = generate_series(date_min, date_max, 60 * 25 , \"time_span25min\")\n",
    "time_series30_df = generate_series(date_min, date_max, 60 * 30 , \"time_span30min\")\n",
    "# time_series35_df = generate_series(date_min, date_max, 60 * 35 , \"time_span35min\")\n",
    "# time_series40_df = generate_series(date_min, date_max, 60 * 40 , \"time_span40min\")\n",
    "# time_series45_df = generate_series(date_min, date_max, 60 * 45 , \"time_span45min\")\n",
    "# time_series50_df = generate_series(date_min, date_max, 60 * 50 , \"time_span50min\")\n",
    "# time_series55_df = generate_series(date_min, date_max, 60 * 55 , \"time_span55min\")\n",
    "# time_series59_df = generate_series(date_min, date_max, 60 * 59 , \"time_span59min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_span10min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-01 01:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-01 01:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-01 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-01 01:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time_span10min\n",
       "0 2019-05-01 01:00:00\n",
       "1 2019-05-01 01:10:00\n",
       "2 2019-05-01 01:20:00\n",
       "3 2019-05-01 01:30:00\n",
       "4 2019-05-01 01:40:00"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series10_df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_span5_df = time_series5_df.withColumn(\"next_time_span5min\",F.lead(\"time_span5min\").over(Window.orderBy(time_series5_df.time_span5min)))\n",
    "time_span10_df = time_series10_df.withColumn(\"next_time_span10min\",F.lead(\"time_span10min\").over(Window.orderBy(time_series10_df.time_span10min)))\n",
    "time_span15_df = time_series15_df.withColumn(\"next_time_span15min\",F.lead(\"time_span15min\").over(Window.orderBy(time_series15_df.time_span15min)))\n",
    "time_span20_df = time_series20_df.withColumn(\"next_time_span20min\",F.lead(\"time_span20min\").over(Window.orderBy(time_series20_df.time_span20min)))\n",
    "\n",
    "time_span25_df = time_series25_df.withColumn(\"next_time_span25min\",F.lead(\"time_span25min\").over(Window.orderBy(time_series25_df.time_span25min)))\n",
    "time_span30_df = time_series30_df.withColumn(\"next_time_span30min\",F.lead(\"time_span30min\").over(Window.orderBy(time_series30_df.time_span30min)))\n",
    "\n",
    "# time_span35_df = time_series35_df.withColumn(\"next_time_span35min\",F.lead(\"time_span35min\").over(Window.orderBy(time_series35_df.time_span35min)))\n",
    "# time_span40_df = time_series40_df.withColumn(\"next_time_span40min\",F.lead(\"time_span40min\").over(Window.orderBy(time_series40_df.time_span40min)))\n",
    "# time_span45_df = time_series45_df.withColumn(\"next_time_span45min\",F.lead(\"time_span45min\").over(Window.orderBy(time_series45_df.time_span45min)))\n",
    "# time_span50_df = time_series50_df.withColumn(\"next_time_span50min\",F.lead(\"time_span50min\").over(Window.orderBy(time_series50_df.time_span50min)))\n",
    "# time_span55_df = time_series55_df.withColumn(\"next_time_span55min\",F.lead(\"time_span55min\").over(Window.orderBy(time_series55_df.time_span55min)))\n",
    "# time_span59_df = time_series59_df.withColumn(\"next_time_span59min\",F.lead(\"time_span59min\").over(Window.orderBy(time_series59_df.time_span59min)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_span10min</th>\n",
       "      <th>next_time_span10min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-01 01:00:00</td>\n",
       "      <td>2019-05-01 01:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-01 01:10:00</td>\n",
       "      <td>2019-05-01 01:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-01 01:20:00</td>\n",
       "      <td>2019-05-01 01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-01 01:30:00</td>\n",
       "      <td>2019-05-01 01:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-01 01:40:00</td>\n",
       "      <td>2019-05-01 01:50:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time_span10min next_time_span10min\n",
       "0 2019-05-01 01:00:00 2019-05-01 01:10:00\n",
       "1 2019-05-01 01:10:00 2019-05-01 01:20:00\n",
       "2 2019-05-01 01:20:00 2019-05-01 01:30:00\n",
       "3 2019-05-01 01:30:00 2019-05-01 01:40:00\n",
       "4 2019-05-01 01:40:00 2019-05-01 01:50:00"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_span10_df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter(\"busstop_number == 150751\")\n",
    "events = (df.join(time_span5_df, (df.event_timestamp >= time_span5_df.time_span5min)\n",
    "               & (df.event_timestamp < time_span5_df.next_time_span5min ))\n",
    "         )\n",
    "\n",
    "events = (events.join(time_span10_df, (events.event_timestamp >= time_span10_df.time_span10min)\n",
    "               & (events.event_timestamp < time_span10_df.next_time_span10min ))\n",
    "         )\n",
    "\n",
    "events = (events.join(time_span15_df, (events.event_timestamp >= time_span15_df.time_span15min)\n",
    "               & (events.event_timestamp < time_span15_df.next_time_span15min ))\n",
    "         )\n",
    "\n",
    "events = (events.join(time_span20_df, (events.event_timestamp >= time_span20_df.time_span20min)\n",
    "               & (events.event_timestamp < time_span20_df.next_time_span20min ))\n",
    "         )\n",
    "\n",
    "events = (events.join(time_span25_df, (events.event_timestamp >= time_span25_df.time_span25min)\n",
    "               & (events.event_timestamp < time_span25_df.next_time_span25min ))\n",
    "         )\n",
    "\n",
    "events = (events.join(time_span30_df, (events.event_timestamp >= time_span30_df.time_span30min)\n",
    "               & (events.event_timestamp < time_span30_df.next_time_span30min ))\n",
    "         )\n",
    "\n",
    "\n",
    "# events = (events.join(time_span35_df, (events.event_timestamp >= time_span35_df.time_span35min)\n",
    "#                & (events.event_timestamp < time_span35_df.next_time_span35min ))\n",
    "#          )\n",
    "\n",
    "# events = (events.join(time_span40_df, (events.event_timestamp >= time_span40_df.time_span40min)\n",
    "#                & (events.event_timestamp < time_span40_df.next_time_span40min ))\n",
    "#          )\n",
    "\n",
    "# events = (events.join(time_span45_df, (events.event_timestamp >= time_span45_df.time_span45min)\n",
    "#                & (events.event_timestamp < time_span45_df.next_time_span45min ))\n",
    "#          )\n",
    "\n",
    "# events = (events.join(time_span50_df, (events.event_timestamp >= time_span50_df.time_span50min)\n",
    "#                & (events.event_timestamp < time_span50_df.next_time_span50min ))\n",
    "#          )\n",
    "\n",
    "\n",
    "# events = (events.join(time_span55_df, (events.event_timestamp >= time_span55_df.time_span55min)\n",
    "#                & (events.event_timestamp < time_span55_df.next_time_span55min ))\n",
    "#          )\n",
    "\n",
    "\n",
    "# events = (events.join(time_span59_df, (events.event_timestamp >= time_span59_df.time_span59min)\n",
    "#                & (events.event_timestamp < time_span59_df.next_time_span59min ))\n",
    "#          )\n",
    "\n",
    "events = events.orderBy(F.desc(\"busstop_number\"),F.asc(\"event_timestamp\")).drop(\"event_timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#events.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "window5 = (\n",
    "    Window.partitionBy(events.year, events.month, events.day, events.busstop_number,events.name, events.latitude, events.longitude, events.time_span5min,events.next_time_span5min)\n",
    ")\n",
    "\n",
    "window10 = (\n",
    "    Window.partitionBy(events.year, events.month, events.day, events.busstop_number,events.name, events.latitude, events.longitude, events.time_span10min,events.next_time_span10min)\n",
    ")\n",
    "\n",
    "window15 = (\n",
    "    Window.partitionBy(events.year, events.month, events.day, events.busstop_number,events.name, events.latitude, events.longitude, events.time_span15min,events.next_time_span15min)\n",
    ")\n",
    "\n",
    "window20 = (\n",
    "    Window.partitionBy(events.year, events.month, events.day, events.busstop_number,events.name, events.latitude, events.longitude, events.time_span20min,events.next_time_span20min)\n",
    ")\n",
    "\n",
    "window25 = (\n",
    "    Window.partitionBy(events.year, events.month, events.day, events.busstop_number,events.name, events.latitude, events.longitude, events.time_span25min,events.next_time_span25min)\n",
    ")\n",
    "\n",
    "window30 = (\n",
    "    Window.partitionBy(events.year, events.month, events.day, events.busstop_number,events.name, events.latitude, events.longitude, events.time_span30min,events.next_time_span30min)\n",
    ")\n",
    "\n",
    "\n",
    "events2 = (events\n",
    "          .withColumn(\"count_lines5min\", F.size(F.collect_set('line_code').over(window5)))\n",
    "          .withColumn(\"count_vehicles5min\", F.size(F.collect_set('vehicle').over(window5)))\n",
    "          .withColumn(\"set_vehicles5min\", F.collect_set('vehicle').over(window5))\n",
    "          .withColumn(\"set_lines5min\", F.collect_set('line_code').over(window5))\n",
    "           \n",
    "           .withColumn(\"count_lines10min\", F.size(F.collect_set('line_code').over(window10)))\n",
    "          .withColumn(\"count_vehicles10min\", F.size(F.collect_set('vehicle').over(window10)))\n",
    "          .withColumn(\"set_vehicles10min\", F.collect_set('vehicle').over(window10))\n",
    "          .withColumn(\"set_lines10min\", F.collect_set('line_code').over(window10))\n",
    "           \n",
    "           .withColumn(\"count_lines15min\", F.size(F.collect_set('line_code').over(window15)))\n",
    "          .withColumn(\"count_vehicles15min\", F.size(F.collect_set('vehicle').over(window15)))\n",
    "          .withColumn(\"set_vehicles15min\", F.collect_set('vehicle').over(window15))\n",
    "          .withColumn(\"set_lines15min\", F.collect_set('line_code').over(window15))\n",
    "           \n",
    "           .withColumn(\"count_lines20min\", F.size(F.collect_set('line_code').over(window20)))\n",
    "          .withColumn(\"count_vehicles20min\", F.size(F.collect_set('vehicle').over(window20)))\n",
    "          .withColumn(\"set_vehicles20min\", F.collect_set('vehicle').over(window20))\n",
    "          .withColumn(\"set_lines20min\", F.collect_set('line_code').over(window20))\n",
    "           \n",
    "           .withColumn(\"count_lines25min\", F.size(F.collect_set('line_code').over(window25)))\n",
    "          .withColumn(\"count_vehicles25min\", F.size(F.collect_set('vehicle').over(window25)))\n",
    "          .withColumn(\"set_vehicles25min\", F.collect_set('vehicle').over(window25))\n",
    "          .withColumn(\"set_lines25min\", F.collect_set('line_code').over(window25))\n",
    "           \n",
    "          .withColumn(\"count_lines30min\", F.size(F.collect_set('line_code').over(window30)))\n",
    "          .withColumn(\"count_vehicles30min\", F.size(F.collect_set('vehicle').over(window30)))\n",
    "          .withColumn(\"set_vehicles30min\", F.collect_set('vehicle').over(window30))\n",
    "          .withColumn(\"set_lines30min\", F.collect_set('line_code').over(window30))\n",
    "          \n",
    "          .orderBy(F.desc(\"busstop_number\"),F.asc(\"time_span5min\"))).drop(\"vehicle\",\"line_code\",\"line_way\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frequencies = events2.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frequencies.to_csv(\"frequencies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
